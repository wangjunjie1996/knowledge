# Go语言并发
并发指在同一时间内可以执行多个任务。并发编程含义比较广泛，包含多线程编程、多进程编程及分布式程序等。本章讲解的并发含义属于多线程编程。

Go 语言通过编译器运行时（runtime），从语言上支持了并发的特性。Go 语言的并发通过goroutine特性完成。goroutine 类似于线程，但是可以根据需要创建多个 goroutine 并发工作。goroutine 是由 Go 语言的运行时调度完成，而线程是由操作系统调度完成。

Go 语言还提供channel在多个 goroutine 间进行通信。goroutine 和 channel 是 Go 语言秉承的 CSP（Communicating Sequential Process）并发模式的重要实现基础。本章中，将详细为大家讲解 goroutine 和 channel 及相关特性。
## Go语言并发简述（并发的优势）
### 进程/线程
```
进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。
线程是进程的一个执行实体，是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。
一个进程可以创建和撤销多个线程，同一个进程中的多个线程之间可以并发执行
```
### 并发/并行
```
多线程程序在单核心的 cpu 上运行，称为并发；多线程程序在多核心的 cpu 上运行，称为并行。
并发与并行并不相同，并发主要由切换时间片来实现“同时”运行，并行则是直接利用多核实现多线程的运行，Go程序可以设置使用核心数，以发挥多核计算机的能力。
```
### 协程/线程
```
协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。
线程：一个线程上可以跑多个协程，协程是轻量级的线程。
优雅的并发编程范式，完善的并发支持，出色的并发性能是Go语言区别于其他语言的一大特色。使用Go语言开发服务器程序时，就需要对它的并发机制有深入的了解。
```
## Go语言goroutine（轻量级线程）
goroutine 是一种非常轻量级的实现，可在单个进程里执行成千上万的并发任务，它是Go语言并发设计的核心,由 Go 运行时（runtime）管理。Go 程序会智能地将 goroutine 中的任务合理地分配给每个 CPU。

Go 程序从 main 包的 main() 函数开始，在程序启动时，Go 程序就会为 main() 函数创建一个默认的 goroutine。

说到底 goroutine 其实就是线程，但是它比线程更小，十几个 goroutine 可能体现在底层就是五六个线程，而且Go语言内部也实现了 goroutine 之间的内存共享。

使用 go 关键字就可以创建 goroutine，将 go 声明放到一个需调用的函数之前，在相同地址空间调用运行这个函数，这样该函数执行时便会作为一个独立的并发线程，这种线程在Go语言中则被称为 goroutine。

goroutine 的用法如下：
```
//go 关键字放在方法调用前新建一个 goroutine 并执行方法体
go GetThingDone(param1, param2);
//新建一个匿名方法并执行
go func(param1, param2) {}(val1, val2)
//直接新建一个 goroutine 并在 goroutine 中执行代码块go {    //do someting...}
```
因为 goroutine 在多核 cpu 环境下是并行的，如果代码块在多个 goroutine 中执行，那么我们就实现了代码的并行。

如果需要了解程序的执行情况，怎么拿到并行的结果呢？需要配合使用channel进行。
## Go语言并发通信
Go语言提供的是另一种通信模型，即以消息机制而非共享内存作为通信方式。消息机制认为每个并发单元是自包含的、独立的个体，并且都有自己的变量，但在不同并发单元间这些变量不共享。每个并发单元的输入和输出只有一种，那就是消息。这有点类似于进程的概念，每个进程不会被其他进程打扰，它只做好自己的工作就可以了。不同进程间靠消息来通信，它们不会共享内存。Go语言提供的消息通信机制被称为 channel
## Go语言竞争状态简述
```
有并发，就有资源竞争，如果两个或者多个 goroutine 在没有相互同步的情况下，访问某个共享的资源，比如同时对该资源进行读写时，就会处于相互竞争的状态，这就是并发中的资源竞争。
并发本身并不复杂，但是因为有了资源竞争的问题，就使得我们开发出好的并发程序变得复杂起来，因为会引起很多莫名其妙的问题。
下面的代码中就会出现竞争状态：
package main
import (
    "fmt"
    "runtime"
    "sync"
)
var (
    count int32
    wg    sync.WaitGroup)
func main() {
    wg.Add(2)
    go incCount()
    go incCount()
    wg.Wait()
    fmt.Println(count)
}
func incCount() {
    defer wg.Done()
    for i := 0; i < 2; i++ {
        value := count
        runtime.Gosched()
        value++
        count = value
    }
}
这是一个资源竞争的例子，大家可以将程序多运行几次，会发现结果可能是 2，也可以是 3，还可能是 4。这是因为 count 变量没有任何同步保护，所以两个 goroutine 都会对其进行读写，会导致对已经计算好的结果被覆盖，以至于产生错误结果。
代码中的 runtime.Gosched() 是让当前 goroutine 暂停的意思，退回执行队列，让其他等待的 goroutine 运行，目的是为了使资源竞争的结果更明显。
Go 为我们提供了一个工具帮助我们检查，这个就是go build -race命令。在项目目录下执行这个命令，生成一个可以执行文件，然后再运行这个可执行文件，就可以看到打印出的检测信息。
在go build命令中多加了一个-race标志，这样生成的可执行程序就自带了检测资源竞争的功能，运行生成的可执行文件，效果如下所示：

==================
WARNING: DATA RACE
Read at 0x000000619cbc by goroutine 8:
  main.incCount()
      D:/code/src/main.go:25 +0x80

Previous write at 0x000000619cbc by goroutine 7:
  main.incCount()
      D:/code/src/main.go:28 +0x9f

Goroutine 8 (running) created at:
  main.main()
      D:/code/src/main.go:17 +0x7e

Goroutine 7 (finished) created at:
  main.main()
      D:/code/src/main.go:16 +0x66
==================
4
Found 1 data race(s)

通过运行结果可以看出 goroutine 8 在代码 25 行读取共享资源value := count，而这时 goroutine 7 在代码 28 行修改共享资源count = value，而这两个 goroutine 都是从 main 函数的 16、17 行通过 go 关键字启动的。
```
### 锁住共享资源
Go语言提供了传统的同步 goroutine 的机制，就是对共享资源加锁。atomic 和 sync 包里的一些函数就可以对共享的资源进行加锁操作。
#### 原子函数
原子函数能够以很底层的加锁机制来同步访问整型变量和指针，示例代码如下所示：
```go
package main
import (
    "fmt"
    "runtime"
    "sync"
    "sync/atomic"
)
var (
    counter int64
    wg      sync.WaitGroup
)
func main() {
    wg.Add(2)
    go incCounter(1)
    go incCounter(2)
    wg.Wait() //等待goroutine结束
    fmt.Println(counter)
}
func incCounter(id int) {
    defer wg.Done()
    for count := 0; count < 2; count++ {
        atomic.AddInt64(&counter, 1) //安全的对counter加1
        runtime.Gosched()
    }
}
```
上述代码中使用了 atmoic 包的 AddInt64 函数，这个函数会同步整型值的加法，方法是强制同一时刻只能有一个 gorountie 运行并完成这个加法操作。当 goroutine 试图去调用任何原子函数时，这些 goroutine 都会自动根据所引用的变量做同步处理。

另外两个有用的原子函数是 LoadInt64 和 StoreInt64。这两个函数提供了一种安全地读和写一个整型值的方式。下面是代码就使用了 LoadInt64 和 StoreInt64 函数来创建一个同步标志，这个标志可以向程序里多个 goroutine 通知某个特殊状态。
```go
package main
import (
    "fmt"
    "sync"
    "sync/atomic"
    "time"
)
var (
    shutdown int64
    wg       sync.WaitGroup
)
func main() {
    wg.Add(2)
    go doWork("A")
    go doWork("B")
    time.Sleep(1 * time.Second)
    fmt.Println("Shutdown Now")
    atomic.StoreInt64(&shutdown, 1)
    wg.Wait()
}
func doWork(name string) {
    defer wg.Done()
    for {
        fmt.Printf("Doing %s Work\n", name)
        time.Sleep(250 * time.Millisecond)
        if atomic.LoadInt64(&shutdown) == 1 {
            fmt.Printf("Shutting %s Down\n", name)
            break
        }
    }
}
```
上面代码中 main 函数使用 StoreInt64 函数来安全地修改 shutdown 变量的值。如果哪个 doWork goroutine 试图在 main 函数调用 StoreInt64 的同时调用 LoadInt64 函数，那么原子函数会将这些调用互相同步，保证这些操作都是安全的，不会进入竞争状态。
#### 互斥锁
另一种同步访问共享资源的方式是使用互斥锁，互斥锁这个名字来自互斥的概念。互斥锁用于在代码上创建一个临界区，保证同一时间只有一个 goroutine 可以执行这个临界代码。
```go
package main
import (
    "fmt"
    "runtime"
    "sync"
)
var (
    counter int64
    wg      sync.WaitGroup
    mutex   sync.Mutex
)
func main() {
    wg.Add(2)
    go incCounter(1)
    go incCounter(2)
    wg.Wait()
    fmt.Println(counter)
}
func incCounter(id int) {
    defer wg.Done()
    for count := 0; count < 2; count++ {
        //同一时刻只允许一个goroutine进入这个临界区
        mutex.Lock(){
            value := counter
            runtime.Gosched()
            value++
            counter = value
        }
        mutex.Unlock() //释放锁，允许其他正在等待的goroutine进入临界区
    }
}
```
同一时刻只有一个 goroutine 可以进入临界区。之后直到调用 Unlock 函数之后，其他 goroutine 才能进去临界区。当调用 runtime.Gosched 函数强制将当前 goroutine 退出当前线程后，调度器会再次分配这个 goroutine 继续运行。
## Go语言GOMAXPROCS（调整并发的运行性能）
在 Go语言程序运行时（runtime）实现了一个小型的任务调度器。这套调度器的工作原理类似于操作系统调度线程，Go 程序调度器可以高效地将 CPU 资源分配给每一个任务。传统逻辑中，开发者需要维护线程池中线程与 CPU 核心数量的对应关系。同样的，Go 地中也可以通过 runtime.GOMAXPROCS() 函数做到，格式为：

runtime.GOMAXPROCS(逻辑CPU数量)

这里的逻辑CPU数量可以有如下几种数值：
* <1：不修改任何数值。
* =1：单核心执行。
* >1：多核并发执行。
一般情况下，可以使用 runtime.NumCPU() 查询 CPU 数量，并使用 runtime.GOMAXPROCS() 函数进行设置，例如：
```
runtime.GOMAXPROCS(runtime.NumCPU())
```
Go 1.5 版本之前，默认使用的是单核心执行。从 Go 1.5 版本开始，默认执行上面语句以便让代码并发执行，最大效率地利用 CPU。

GOMAXPROCS 同时也是一个环境变量，在应用程序启动前设置环境变量也可以起到相同的作用。
## 并发和并行的区别
* 并发（concurrency）：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务并不会同时运行。
* 并行（parallelism）：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务一定是同时运行。
在很多情况下，并发的效果比并行好，因为操作系统和硬件的总资源一般很少，但能支持系统同时做很多事情。这种“使用较少的资源做更多的事情”的哲学，也是指导 Go语言设计的哲学。

如果希望让 goroutine 并行，必须使用多于一个逻辑处理器。当有多个逻辑处理器时，调度器会将 goroutine 平等分配到每个逻辑处理器上。这会让 goroutine 在不同的线程上运行。不过要想真的实现并行的效果，用户需要让自己的程序运行在有多个物理处理器的机器上。否则，哪怕 Go语言运行时使用多个线程，goroutine 依然会在同一个物理处理器上并发运行，达不到并行的效果。

Go语言在 GOMAXPROCS 数量与任务数量相等时，可以做到并行执行，但一般情况下都是并发执行。
## goroutine和coroutine的区别
C#、Lua、Python语言都支持 coroutine 特性。coroutine 与 goroutine 在名字上类似，都可以将函数或者语句在独立的环境中运行，但是它们之间有两点不同：
* goroutine 可能发生并行执行；
* 但 coroutine 始终顺序执行。
goroutine 可能发生在多线程环境下，goroutine 无法控制自己获取高优先度支持；coroutine 始终发生在单线程，coroutine 程序需要主动交出控制权，宿主才能获得控制权并将控制权交给其他 coroutine。

goroutine 间使用 channel 通信，coroutine 使用 yield 和 resume 操作。

goroutine 和 coroutine 的概念和运行机制都是脱胎于早期的操作系统。
## channel
```
channel 是Go语言在语言级别提供的 goroutine 间的通信方式。我们可以使用 channel 在两个或多个 goroutine 之间传递消息。
channel 是进程内的通信方式，因此通过 channel 传递对象的过程和调用函数时的参数传递行为比较一致，比如也可以传递指针等。如果需要跨进程通信，我们建议用分布式系统的方法来解决，比如使用 Socket 或者 HTTP 等通信协议。Go语言对于网络方面也有非常完善的支持。
channel 是类型相关的，也就是说，一个 channel 只能传递一种类型的值，这个类型需要在声明 channel 时指定。如果对 Unix 管道有所了解的话，就不难理解 channel，可以将其认为是一种类型安全的管道。
```
定义一个 channel 时，也需要定义发送到 channel 的值的类型，注意，必须使用 make 创建 channel，代码如下所示：
```
ci := make(chan int)cs := make(chan string)cf := make(chan interface{})
```
## Go语言通道（chan）——goroutine之间通信的管道
如果说 goroutine 是 Go语言程序的并发体的话，那么 channels 就是它们之间的通信机制。一个 channels 是一个通信机制，它可以让一个 goroutine 通过它给另一个 goroutine 发送值信息。每个 channel 都有一个特殊的类型，也就是 channels 可发送数据的类型。一个可以发送 int 类型数据的 channel 一般写为 chan int。

Go语言提倡使用通信的方法代替共享内存，当一个资源需要在 goroutine 之间共享时，通道在 goroutine 之间架起了一个管道，并提供了确保同步交换数据的机制。声明通道时，需要指定将要被共享的数据的类型。可以通过通道共享内置类型、命名类型、结构类型和引用类型的值或者指针。
### 通道的特性
Go语言中的通道（channel）是一种特殊的类型。在任何时候，同时只能有一个 goroutine 访问通道进行发送和获取数据。goroutine 间通过通道就可以通信。

通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。
### 声明通道类型
通道本身需要一个类型进行修饰，就像切片类型需要标识元素类型。通道的元素类型就是在其内部传输的数据类型，声明如下：
```
var 通道变量 chan 通道类型
```
* 通道类型：通道内的数据类型。
* 通道变量：保存通道的变量。
chan 类型的空值是 nil，声明后需要配合 make 后才能使用。
### 创建通道
通道是引用类型，需要使用 make 进行创建，格式如下：

通道实例 := make(chan 数据类型)
* 数据类型：通道内传输的元素类型。
* 通道实例：通过make创建的通道句柄。
```go
ch1 := make(chan int)  // 创建一个整型类型的通道
ch2 := make(chan interface{})  // 创建一个空接口类型的通道, 可以存放任意格式
type Equip struct{ /* 一些字段 */ }
ch2 := make(chan *Equip) // 创建Equip指针类型的通道, 可以存放*Equip
```
### 使用通道发送数据
通道创建后，就可以使用通道进行发送和接收操作。
1. 通道发送数据的格式
```
通道的发送使用特殊的操作符<-，将数据通过通道发送的格式为：
通道变量 <- 值
* 通道变量：通过make创建好的通道实例。
* 值：可以是变量、常量、表达式或者函数返回值等。值的类型必须与ch通道的元素类型一致。
```
2. 通过通道发送数据的例子
使用 make 创建一个通道后，就可以使用<-向通道发送数据，代码如下：
```go
// 创建一个空接口通道
ch := make(chan interface{})
// 将0放入通道中
ch <- 0
// 将hello字符串放入通道中
ch <- "hello"
```
3. 发送将持续阻塞直到数据被接收
把数据往通道中发送时，如果接收方一直都没有接收，那么发送操作将持续阻塞。Go 程序运行时能智能地发现一些永远无法发送成功的语句并做出提示，代码如下：
```go
package mainfunc main() {
    // 创建一个整型通道
    ch := make(chan int)
    // 尝试将0通过通道发送
    ch <- 0
}
```
运行代码，报错： fatal error: all goroutines are asleep - deadlock!

报错的意思是：运行时发现所有的 goroutine（包括main）都处于等待 goroutine。也就是说所有 goroutine 中的 channel 并没有形成发送和接收对应的代码。
### 使用通道接收数据
```
通道接收同样使用<-操作符，通道接收有如下特性：
① 通道的收发操作在不同的两个 goroutine 间进行。
由于通道的数据在没有接收方处理时，数据发送方会持续阻塞，因此通道的接收必定在另外一个 goroutine 中进行。
② 接收将持续阻塞直到发送方发送数据。
如果接收方接收时，通道中没有发送方发送数据，接收方也会发生阻塞，直到发送方发送数据为止。
③ 每次接收一个元素。
通道一次只能接收一个数据元素。
通道的数据接收一共有以下 4 种写法。
1) 阻塞接收数据
阻塞模式接收数据时，将接收变量作为<-操作符的左值，格式如下：
data := <-ch
执行该语句时将会阻塞，直到接收到数据并赋值给 data 变量。
2) 非阻塞接收数据
使用非阻塞方式从通道接收数据时，语句不会发生阻塞，格式如下：
data, ok := <-ch
* data：表示接收到的数据。未接收到数据时，data 为通道类型的零值。
* ok：表示是否接收到数据。
非阻塞的通道接收方法可能造成高的 CPU 占用，因此使用非常少。如果需要实现接收超时检测，可以配合 select 和计时器 channel 进行，可以参见后面的内容。
3) 接收任意数据，忽略接收的数据
阻塞接收数据后，忽略从通道返回的数据，格式如下：
<-ch
执行该语句时将会发生阻塞，直到接收到数据，但接收到的数据会被忽略。这个方式实际上只是通过通道在 goroutine 间阻塞收发实现并发同步。
使用通道做并发同步的写法，可以参考下面的例子：

package main
import (
    "fmt"
)
func main() {
    // 构建一个通道
    ch := make(chan int)
    // 开启一个并发匿名函数
    go func() {
        fmt.Println("start goroutine")
        // 通过通道通知main的goroutine
        ch <- 0
        fmt.Println("exit goroutine")
    }()
    fmt.Println("wait goroutine")
    // 等待匿名goroutine
    <-ch
    fmt.Println("all done")
}
执行代码，输出如下：
wait goroutine
start goroutine
exit goroutine
all done
4) 循环接收
通道的数据接收可以借用 for range 语句进行多个元素的接收操作，格式如下：
for data := range ch {}
通道 ch 是可以进行遍历的，遍历的结果就是接收到的数据。数据类型就是通道的数据类型。通过 for 遍历获得的变量只有一个，即上面例子中的 data。
```
## Go语言并发打印（借助通道实现）
通过一个并发打印的例子，将 goroutine 和 channel 放在一起展示它们的用法。
```go
package main
import (
    "fmt"
)
func printer(c chan int) {
    // 开始无限循环等待数据
    for {
        // 从channel中获取一个数据
        data := <-c
        // 将0视为数据结束
        if data == 0 {
            break
        }
        // 打印数据
        fmt.Println(data)
    }
    // 通知main已经结束循环(我搞定了!)
    c <- 0
}
func main() {
    // 创建一个channel
    c := make(chan int)
    // 并发执行printer, 传入channel
    go printer(c)
    for i := 1; i <= 10; i++ {
        // 将数据通过channel投送给printer
        c <- i
    }
    // 通知并发的printer结束循环(没数据啦!)
    c <- 0
    // 等待printer结束(搞定喊我!)
    <-c
}

```
## Go语言单向通道——通道中的单行道
单向 channel 只能用于发送或者接收数据。channel 本身必然是同时支持读写的，否则根本没法用。

假如一个 channel 真的只能读，那么肯定只会是空的，因为你没机会往里面写数据。同理，如果一个 channel 只允许写，即使写进去了，也没有丝毫意义，因为没有机会读取里面的数据。所谓的单向 channel 概念，其实只是对 channel 的一种使用限制。
### 单向通道的声明格式
我们在将一个 channel 变量传递到一个函数时，可以通过将其指定为单向 channel 变量，从而限制该函数中可以对此 channel 的操作，比如只能往这个 channel 写，或者只能从这个 channel 读。

单向 channel 变量的声明非常简单，只能发送的通道类型为chan<-，只能接收的通道类型为<-chan，格式如下：
```
var 通道实例 chan<- 元素类型    // 只能发送通道
var 通道实例 <-chan 元素类型    // 只能接收通道
元素类型：通道包含的元素类型。
通道实例：声明的通道变量。
```
### 单向通道的使用例子
```go
ch := make(chan int)
// 声明一个只能发送的通道类型, 并赋值为ch
var chSendOnly chan<- int = ch
//声明一个只能接收的通道类型, 并赋值为ch
var chRecvOnly <-chan int = ch
```
当然，使用 make 创建通道时，也可以创建一个只写入或只读取的通道：
```go
    ch := make(<-chan int)
    var chReadOnly <-chan int = ch
    <-chReadOnly
```
### time包中的单向通道
time 包中的计时器会返回一个 timer 实例，代码如下：
```
timer := time.NewTimer(time.Second)
```
timer的Timer类型定义如下：
```
type Timer struct {    C <-chan Time    r runtimeTimer}
```
第 2 行中 C 通道的类型就是一种只能接收的单向通道。如果此处不进行通道方向约束，一旦外部向通道发送数据，将会造成其他使用到计时器的地方逻辑产生混乱。

因此，单向通道有利于代码接口的严谨性。
### 关闭 channel
```
关闭 channel 非常简单，直接使用 Go语言内置的 close() 函数即可：
close(ch)
在介绍了如何关闭 channel 之后，我们就多了一个问题：如何判断一个 channel 是否已经被关闭？我们可以在读取的时候使用多重返回值的方式：
x, ok := <-ch
这个用法与 map 中的按键获取 value 的过程比较类似，只需要看第二个 bool 返回值即可，如果返回值是 false 则表示 ch 已经被关闭。
```
## Go语言无缓冲的通道
```
Go语言中无缓冲的通道（unbuffered channel）是指在接收前没有能力保存任何值的通道。这种类型的通道要求发送 goroutine 和接收 goroutine 同时准备好，才能完成发送和接收操作。
如果两个 goroutine 没有同时准备好，通道会导致先执行发送或接收操作的 goroutine 阻塞等待。这种对通道进行发送和接收的交互行为本身就是同步的。其中任意一个操作都无法离开另一个操作单独存在。
阻塞指的是由于某种原因数据没有到达，当前协程（线程）持续处于等待状态，直到条件满足才解除阻塞。
同步指的是在两个或多个协程（线程）之间，保持数据内容一致性的机制。
```
## Go语言带缓冲的通道
```
Go语言中有缓冲的通道（buffered channel）是一种在被接收前能存储一个或者多个值的通道。这种类型的通道并不强制要求 goroutine 之间必须同时完成发送和接收。通道会阻塞发送和接收动作的条件也会不同。只有在通道中没有要接收的值时，接收动作才会阻塞。只有在通道没有可用缓冲区容纳被发送的值时，发送动作才会阻塞。
无缓冲的通道保证进行发送和接收的 goroutine 会在同一时间进行数据交换；有缓冲的通道没有这种保证。
在无缓冲通道的基础上，为通道增加一个有限大小的存储空间形成带缓冲通道。
```
### 创建带缓冲通道
通道实例 := make(chan 通道类型, 缓冲大小)  
```go
package main
import "fmt"
func main() {    
    // 创建一个3个元素缓冲大小的整型通道    
    ch := make(chan int, 3)    
    // 查看当前通道的大小    
    fmt.Println(len(ch))    
    // 发送3个整型元素到通道    
    ch <- 1    
    ch <- 2    
    ch <- 3    
    // 查看当前通道的大小    
    fmt.Println(len(ch))}
```
代码输出如下：
```
0
3
```
### 阻塞条件
带缓冲通道在很多特性上和无缓冲通道是类似的。无缓冲通道可以看作是长度永远为 0 的带缓冲通道。因此根据这个特性，带缓冲通道在下面列举的情况下依然会发生阻塞：
* 带缓冲通道被填满时，尝试再次发送数据时发生阻塞。
* 带缓冲通道为空时，尝试接收数据时发生阻塞。
## Go语言channel超时机制
可以使用 select 来设置超时,虽然 select 机制不是专门为超时而设计的，却能很方便的解决超时问题，因为 select 的特点是只要其中有一个 case 已经完成，程序就会继续往下执行，而不会考虑其他 case 的情况。  
与 switch 语句相比，select 有比较多的限制，其中最大的一条限制就是每个 case 语句里必须是一个 IO 操作，大致的结构如下：  
```go
select {
    case <-chan1:
    // 如果chan1成功读到数据，则进行该case处理语句
    case chan2 <- 1:
    // 如果成功向chan2写入数据，则进行该case处理语句
    default:
    // 如果上面都没有成功，则进入default处理流程
}
```
在一个 select 语句中，Go语言会按顺序从头至尾评估每一个发送和接收的语句。  
如果其中的任意一语句可以继续执行（即没有被阻塞），那么就从那些可以执行的语句中任意选择一条来使用。  
如果没有任意一条语句可以执行（即所有的通道都被阻塞），那么有如下两种可能的情况：  
* 如果给出了 default 语句，那么就会执行 default 语句，同时程序的执行会从 select 语句后的语句中恢复；
* 如果没有 default 语句，那么 select 语句将被阻塞，直到至少有一个通信可以进行下去。
```go
package main
import (    
    "fmt"    
    "time"
)
func main() {    
    ch := make(chan int)    
    quit := make(chan bool)    
    //新开一个协程    
    go func() {        
        for {            
            select {            
                case num := <-ch:                
                fmt.Println("num = ", num)            
                case <-time.After(3 * time.Second):                
                fmt.Println("超时")                
                quit <- true            
            }        
        }   
    }() //别忘了()    
    for i := 0; i < 5; i++ {        
        ch <- i        
        time.Sleep(time.Second)    
    }    
    <-quit    
    fmt.Println("程序结束")}
```
运行结果如下：
```
num =  0
num =  1
num =  2
num =  3
num =  4
超时
程序结束
```
## Go语言关闭通道后继续使用通道
关闭的通道依然可以被访问，访问被关闭的通道将会发生一些问题。给被关闭通道发送数据将会触发 panic  
从已关闭的通道接收数据时将不会发生阻塞,从已经关闭的通道接收数据或者正在接收数据时，将会接收到通道类型的零值，然后停止阻塞并返回。  
## Go语言多核并行化
Go语言具有支持高并发的特性，可以很方便地实现多线程运算，充分利用多核心 cpu 的性能。  
Go语言实现多核多线程并发运行是非常方便的，下面举个例子：
```go
package main
import (    
    "fmt"
)
func main() {    
    for i := 0; i < 5; i++ {        
        go AsyncFunc(i)    
    }
}
func AsyncFunc(index int) {    
    sum := 0    
    for i := 0; i < 10000; i++ {        
        sum += 1    
    }    
    fmt.Printf("线程%d, sum为:%d\n", index, sum)
}
```
运行结果如下：
```
线程0, sum为:10000
线程2, sum为:10000
线程3, sum为:10000
线程1, sum为:10000
线程4, sum为:10000
```
当前版本的 Go 编译器还不能很智能地去发现和利用多核的优势。虽然我们确实创建了多个 goroutine，并且从运行状态看这些 goroutine 也都在并行运行，但实际上所有这些 goroutine 都运行在同一个 CPU 核心上，在一个 goroutine 得到时间片执行的时候，其他 goroutine 都会处于等待状态。从这一点可以看出，虽然 goroutine 简化了我们写并行代码的过程，但实际上整体运行效率并不真正高于单线程程序。  
虽然Go语言还不能很好的利用多核心的优势，我们可以先通过设置环境变量 GOMAXPROCS 的值来控制使用多少个 CPU 核心。具体操作方法是通过直接设置环境变量 GOMAXPROCS 的值，或者在代码中启动 goroutine 之前先调用以下这个语句以设置使用 16 个 CPU 核心：runtime.GOMAXPROCS(16)
到底应该设置多少个 CPU 核心呢，其实 runtime 包中还提供了另外一个 NumCPU() 函数来获取核心数，示例代码如下：
```go
package main
import (
    "fmt"
    "runtime"
)
func main() {
    cpuNum := runtime.NumCPU() //获得当前设备的cpu核心数
    fmt.Println("cpu核心数:", cpuNum)
    runtime.GOMAXPROCS(cpuNum) //设置需要用到的cpu数量}
```
## Go语言互斥锁（sync.Mutex）和读写互斥锁（sync.RWMutex）
Go语言包中的 sync 包提供了两种锁类型：sync.Mutex 和 sync.RWMutex。  
Mutex 是最简单的一种锁类型，同时也比较暴力，当一个 goroutine 获得了 Mutex 后，其他 goroutine 就只能乖乖等到这个 goroutine 释放该 Mutex。  
RWMutex 相对友好些，是经典的单写多读模型。在读锁占用的情况下，会阻止写，但不阻止读，也就是多个 goroutine 可同时获取读锁（调用 RLock() 方法；而写锁（调用 Lock() 方法）会阻止任何其他 goroutine（无论读和写）进来，整个锁相当于由该 goroutine 独占。从 RWMutex 的实现看，RWMutex 类型其实组合了 Mutex：
```go
type RWMutex struct {
    w Mutex
    writerSem uint32
    readerSem uint32
    readerCount int32
    readerWait int32
}
```
对于这两种锁类型，任何一个 Lock() 或 RLock() 均需要保证对应有 Unlock() 或 RUnlock() 调用与之对应，否则可能导致等待该锁的所有 goroutine 处于饥饿状态，甚至可能导致死锁。锁的典型使用模式如下：
```go
package main
import (    
    "fmt"    
    "sync"
)
var (    
    // 逻辑中使用的某个变量    
    count int    
    // 与变量对应的使用互斥锁    
    countGuard sync.Mutex
)
func GetCount() int {    
    // 锁定    
    countGuard.Lock()    
    // 在函数退出时解除锁定    
    defer countGuard.Unlock()    
    return count
}
func SetCount(c int) {    
    countGuard.Lock()    
    count = c    
    countGuard.Unlock()
}
func main() {    
    // 可以进行并发安全的设置    
    SetCount(1)    
    // 可以进行并发安全的获取    
    fmt.Println(GetCount())
}
```
## Go语言等待组（sync.WaitGroup）
Go语言中除了可以使用通道（channel）和互斥锁进行两个并发程序间的同步外，还可以使用等待组进行多个任务的同步，等待组可以保证在并发环境中完成指定数量的任务  
在 sync.WaitGroup（等待组）类型中，每个 sync.WaitGroup 值在内部维护着一个计数，此计数的初始默认值为零。  
等待组的方法方法名功能(wg * WaitGroup) Add(delta int)等待组的计数器 +1(wg * WaitGroup) Done()等待组的计数器 -1(wg * WaitGroup) Wait()当等待组计数器不等于 0 时阻塞直到变 0。  
对于一个可寻址的 sync.WaitGroup 值 wg：
* 我们可以使用方法调用 wg.Add(delta) 来改变值 wg 维护的计数。
* 方法调用 wg.Done() 和 wg.Add(-1) 是完全等价的。
* 如果一个 wg.Add(delta) 或者 wg.Done() 调用将 wg 维护的计数更改成一个负数，一个恐慌将产生。
* 当一个协程调用了 wg.Wait() 时，
    * 如果此时 wg 维护的计数为零，则此 wg.Wait() 此操作为一个空操作（noop）；
    * 否则（计数为一个正整数），此协程将进入阻塞状态。当以后其它某个协程将此计数更改至 0 时（一般通过调用 wg.Done()），此协程将重新进入运行状态（即 wg.Wait() 将返回）。
等待组内部拥有一个计数器，计数器的值可以通过方法调用实现计数器的增加和减少。当我们添加了 N 个并发任务进行工作时，就将等待组的计数器值增加 N。每个任务完成时，这个值减 1。同时，在另外一个 goroutine 中等待这个等待组的计数器值为 0 时，表示所有任务已经完成。
```go
package main
import (    
    "fmt"    
    "net/http"    
    "sync"
)
func main() {    
    // 声明一个等待组    
    var wg sync.WaitGroup    
    // 准备一系列的网站地址    
    var urls = []string{        
        "http://www.github.com/",        
        "https://www.qiniu.com/",        
        "https://www.golangtc.com/",    
    }    
    // 遍历这些地址    
    for _, url := range urls {        
        // 每一个任务开始时, 将等待组增加1        
        wg.Add(1)        
        // 开启一个并发        
        go func(url string) {            
            // 使用defer, 表示函数完成时将等待组值减1            
            defer wg.Done()            
            // 使用http访问提供的地址            
            _, err := http.Get(url)            
            // 访问完成后, 打印地址和可能发生的错误            
            fmt.Println(url, err)            
            // 通过参数传递url地址        
        }(url)    
    }    
    // 等待所有的任务完成    
    wg.Wait()    
    fmt.Println("over")}
```
## Go语言死锁、活锁和饥饿概述
### 死锁
死锁是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。  
死锁发生的条件有如下几种：
1. 互斥条件
线程对资源的访问是排他性的，如果一个线程对占用了某资源，那么其他线程必须处于等待状态，直到该资源被释放。
2. 请求和保持条件
线程 T1 至少已经保持了一个资源 R1 占用，但又提出使用另一个资源 R2 请求，而此时，资源 R2 被其他线程 T2 占用，于是该线程 T1 也必须等待，但又对自己保持的资源 R1 不释放。
3. 不剥夺条件
线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。
4. 环路等待条件
在死锁发生时，必然存在一个“进程 - 资源环形链”，即：{p0,p1,p2,...pn}，进程 p0（或线程）等待 p1 占用的资源，p1 等待 p2 占用的资源，pn 等待 p0 占用的资源。

死锁解决办法：
* 如果并发查询多个表，约定访问顺序；
* 在同一个事务中，尽可能做到一次锁定获取所需要的资源；
* 对于容易产生死锁的业务场景，尝试升级锁颗粒度，使用表级锁；
* 采用分布式事务锁或者使用乐观锁。
死锁程序是所有并发进程彼此等待的程序，在这种情况下，如果没有外界的干预，这个程序将永远无法恢复。  
理解死锁
```go
package main
import (    
    "fmt"    
    "runtime"    
    "sync"    
    "time"
)
type value struct {    
    memAccess sync.Mutex    
    value     int
}
func main() {    
    runtime.GOMAXPROCS(3)    
    var wg sync.WaitGroup    
    sum := func(v1, v2 *value) {        
        defer wg.Done()        
        v1.memAccess.Lock()        
        time.Sleep(2 * time.Second)        
        v2.memAccess.Lock()        
        fmt.Printf("sum = %d\n", v1.value+v2.value)        
        v2.memAccess.Unlock()        
        v1.memAccess.Unlock()    
    }    
    product := func(v1, v2 *value) {        
        defer wg.Done()       
         v2.memAccess.Lock()        
         time.Sleep(2 * time.Second)        
         v1.memAccess.Lock()        
         fmt.Printf("product = %d\n", v1.value*v2.value)        
         v1.memAccess.Unlock()        
         v2.memAccess.Unlock()    
    }    
    var v1, v2 value    
    v1.value = 1    
    v2.value = 1    
    wg.Add(2)    
    go sum(&v1, &v2)    
    go product(&v1, &v2)    
    wg.Wait()
}
```
运行上面的代码，可能会看到：
```
fatal error: all goroutines are asleep - deadlock!
```
### 活锁
活锁是另一种形式的活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复同样的操作，而且总会失败。    
活锁通常发生在处理事务消息中，如果不能成功处理某个消息，那么消息处理机制将回滚事务，并将它重新放到队列的开头。这样，错误的事务被一直回滚重复执行，这种形式的活锁通常是由过度的错误恢复代码造成的，因为它错误地将不可修复的错误认为是可修复的错误。  
当多个相互协作的线程都对彼此进行相应而修改自己的状态，并使得任何一个线程都无法继续执行时，就导致了活锁。这就像两个过于礼貌的人在路上相遇，他们彼此让路，然后在另一条路上相遇，然后他们就一直这样避让下去。  
要解决这种活锁问题，需要在重试机制中引入随机性。例如在网络上发送数据包，如果检测到冲突，都要停止并在一段时间后重发，如果都在 1 秒后重发，还是会冲突，所以引入随机性可以解决该类问题。  
下面通过示例来演示一下活锁：
```go
package main

import (
    "bytes"
    "fmt"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

func main() {
    runtime.GOMAXPROCS(3)
    cv := sync.NewCond(&sync.Mutex{})
    go func() {
        for range time.Tick(1 * time.Second) { // 通过tick控制两个人的步调
            cv.Broadcast()
        }
    }()

    takeStep := func() {
        cv.L.Lock()
        cv.Wait()
        cv.L.Unlock()
    }

    tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool {
        fmt.Fprintf(out, " %+v", dirName)
        atomic.AddInt32(dir, 1)
        takeStep()                      //走上一步
        if atomic.LoadInt32(dir) == 1 { //走成功就返回
            fmt.Fprint(out, ". Success!")
            return true
        }
        takeStep() // 没走成功，再走回来
        atomic.AddInt32(dir, -1)
        return false
    }

    var left, right int32
    tryLeft := func(out *bytes.Buffer) bool {
        return tryDir("向左走", &left, out)
    }

    tryRight := func(out *bytes.Buffer) bool {
        return tryDir("向右走", &right, out)
    }

    walk := func(walking *sync.WaitGroup, name string) {
        var out bytes.Buffer
        defer walking.Done()
        defer func() { fmt.Println(out.String()) }()
        fmt.Fprintf(&out, "%v is trying to scoot:", name)

        for i := 0; i < 5; i++ {
            if tryLeft(&out) || tryRight(&out) {
                return
            }
        }
        fmt.Fprintf(&out, "\n%v is tried!", name)
    }

    var trail sync.WaitGroup
    trail.Add(2)
    go walk(&trail, "男人") // 男人在路上走
    go walk(&trail, "女人") // 女人在路上走
    trail.Wait()
}
```
输出结果如下：
```
go run main.go
女人 is trying to scoot: 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走
女人 is tried!
男人 is trying to scoot: 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走
男人 is tried!
```
这个例子演示了使用活锁的一个十分常见的原因，两个或两个以上的并发进程试图在没有协调的情况下防止死锁。这就好比，如果走廊里的人都同意，只有一个人会移动，那就不会有活锁；一个人会站着不动，另一个人会移到另一边，他们就会继续移动。

活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”，而处于死锁的实体表现为等待，活锁有可能自行解开，死锁则不能。
### 饥饿
饥饿是指一个可运行的进程尽管能继续执行，但被调度器无限期地忽视，而不能被调度执行的情况。  
与死锁不同的是，饥饿锁在一段时间内，优先级低的线程最终还是会执行的，比如高优先级的线程执行完之后释放了资源。  
活锁与饥饿是无关的，因为在活锁中，所有并发进程都是相同的，并且没有完成工作。更广泛地说，饥饿通常意味着有一个或多个贪婪的并发进程，它们不公平地阻止一个或多个并发进程，以尽可能有效地完成工作，或者阻止全部并发进程。  